diff --git a/.cursorrules b/.cursorrules
--- ./.cursorrules
+++ ./.cursorrules
@@ -1,4 +1,36 @@
 用中文回答
+在添加新方法之前，先搜索现有代码库中是否已有类似实现
+检查是否可以通过组合现有方法来实现所需功能
+确保不创建重复的功能实现
+要检查一下之前的apply是否正确.
+
+# AI 工作指令
+
+## 核心原则
+1. 专注于用户明确要求的具体任务
+2. 不要主动添加额外的功能或优化
+3. 在修改代码时保持最小改动原则
+
+## 工作流程
+1. 仔细理解用户的具体需求
+2. 确认需要修改的关键部分
+3. 只修改必要的代码
+4. 保持其他代码不变
+
+## 代码修改原则
 1. 在添加新方法之前，先搜索现有代码库中是否已有类似实现
 2. 检查是否可以通过组合现有方法来实现所需功能
 3. 确保不创建重复的功能实现
+4. 只在用户明确要求时才进行重构或优化
+
+## 响应规范
+1. 用中文回答
+2. 清晰说明将要修改的内容
+3. 解释为什么需要这些修改
+4. 只展示必要的代码改动
+
+## 代码展示格式
+1. 使用 markdown 代码块
+2. 标注文件路径和修改位置
+3. 使用注释标明跳过的未修改代码
+4. 重点突出修改的部分
diff --git a/file_processing.go b/file_processing.go
--- ./file_processing.go
+++ ./file_processing.go
@@ -13,11 +13,11 @@ import (
 	"log"
 	"os"
 	"path/filepath"
-	"regexp"
+	"regexp"  // 添加
+	"strconv" // 添加
+	"strings" // 添加
+	"time"    // 添加
 	"sort"
-	"strconv"
-	"strings"
-	"time"
 )
 
 type FileProcessor struct {
@@ -38,7 +38,7 @@ func CreateFileProcessor(rdb *redis.Client, ctx context.Context, excludeRegexps
 		excludeRegexps: excludeRegexps,
 	}
 
-	// 设置默认值
+	// 设置默认
 	fp.generateHashFunc = generateHash
 	fp.calculateFileHashFunc = fp.calculateFileHash
 	fp.saveFileInfoToRedisFunc = saveFileInfoToRedis
@@ -137,20 +137,16 @@ const (
 
 func (fp *FileProcessor) ProcessFile(rootDir, relativePath string, calculateHashes bool) error {
 	fullPath := filepath.Join(rootDir, relativePath)
-	log.Printf("Processing file: %s", fullPath)
 
 	info, err := fp.fs.Stat(fullPath)
 	if err != nil {
 		return fmt.Errorf("error getting file info: %w", err)
 	}
 
-	hashedKey := fp.generateHashFunc(fullPath)
-	log.Printf("Generated hashed key: %s", hashedKey)
-
 	fileInfo := FileInfo{
 		Size:    info.Size(),
 		ModTime: info.ModTime(),
-		Path:    fullPath, // 存储绝对路径
+		Path:    fullPath,
 	}
 
 	var fileHash, fullHash string
@@ -159,24 +155,35 @@ func (fp *FileProcessor) ProcessFile(rootDir, relativePath string, calculateHash
 		if err != nil {
 			return fmt.Errorf("error calculating file hash: %w", err)
 		}
-		log.Printf("Calculated file hash: %s", fileHash)
 
+		exists, err := fp.checkPartialHashExists(fileHash)
+		if err != nil {
+			log.Printf("Warning: Failed to check partial hash: %v", err)
+		} else if exists {
 			fullHash, err = fp.calculateFileHashFunc(fullPath, FullFileReadCmd)
 			if err != nil {
 				return fmt.Errorf("error calculating full file hash: %w", err)
 			}
-		log.Printf("Calculated full hash: %s", fullHash)
+		}
 	}
 
 	err = fp.saveFileInfoToRedisFunc(fp.Rdb, fp.Ctx, fullPath, fileInfo, fileHash, fullHash, calculateHashes)
 	if err != nil {
 		return fmt.Errorf("error saving file info to Redis: %w", err)
 	}
-	log.Printf("Saved file info to Redis")
 
 	return nil
 }
 
+// 新增函数：检查部分hash是否存在
+func (fp *FileProcessor) checkPartialHashExists(partialHash string) (bool, error) {
+	count, err := fp.Rdb.SCard(fp.Ctx, "fileHashToPathSet:"+partialHash).Result()
+	if err != nil {
+		return false, err
+	}
+	return count > 0, nil
+}
+
 type FileInfoRetriever interface {
 	getFileInfoFromRedis(hashedKey string) (FileInfo, error)
 }
@@ -281,10 +288,8 @@ func (fp *FileProcessor) getFileInfoFromRedis(hashedKey string) (FileInfo, error
 }
 
 func (fp *FileProcessor) calculateFileHash(path string, limit int64) (string, error) {
-	// 首先获取文件的 hashedKey
+	// 首先检查缓存
 	hashedKey := fp.generateHashFunc(path)
-	
-	// 检查Redis缓存中是否已存在对应的hash
 	var cacheKey string
 	if limit == FullFileReadCmd {
 		cacheKey = "hashedKeyToFullHash:" + hashedKey
@@ -301,21 +306,20 @@ func (fp *FileProcessor) calculateFileHash(path string, limit int64) (string, er
 	}
 
 	// 缓存未命中，计算新的hash
-	f, err := fp.fs.Open(path)
+	file, err := fp.fs.Open(path)
 	if err != nil {
 		return "", fmt.Errorf("error opening file: %w", err)
 	}
-	defer f.Close()
+	defer file.Close()
 
 	h := sha512.New()
-	if limit == FullFileReadCmd {
-		if _, err := io.Copy(h, f); err != nil {
-			return "", fmt.Errorf("error reading full file: %w", err)
-		}
+	if limit > 0 {
+		_, err = io.CopyN(h, file, limit)
 	} else {
-		if _, err := io.CopyN(h, f, limit); err != nil && err != io.EOF {
-			return "", fmt.Errorf("error reading file: %w", err)
+		_, err = io.Copy(h, file)
 	}
+	if err != nil && err != io.EOF {
+		return "", fmt.Errorf("error reading file: %w", err)
 	}
 
 	hash := fmt.Sprintf("%x", h.Sum(nil))
diff --git a/file_processing_test.go b/file_processing_test.go
--- ./file_processing_test.go
+++ ./file_processing_test.go
@@ -7,18 +7,17 @@ import (
 	"context"
 	"encoding/gob"
 	"fmt"
-	"io/ioutil"
-	"os"
-	"path/filepath"
-	"testing"
-	"time"
-
 	"github.com/alicebob/miniredis/v2"
-	"github.com/go-redis/redis/v8"
 	"github.com/go-redis/redismock/v8"
 	"github.com/spf13/afero"
 	"github.com/stretchr/testify/assert"
 	"github.com/stretchr/testify/require"
+	"github.com/go-redis/redis/v8"
+	"io/ioutil"
+	"os"
+	"path/filepath"
+	"testing"
+	"time"
 )
 
 func setupTestEnvironment(t *testing.T) (*miniredis.Miniredis, *redis.Client, context.Context, afero.Fs, *FileProcessor) {
@@ -375,7 +374,7 @@ func TestExtractTimestamps(t *testing.T) {
 		},
 		{
 			"Timestamps with different formats",
-			"/Users/huangyingw/mini/media/usb_backup_crypt_8T_1/cartoon/dragonball/第一部/龙珠 第一部 日语配音/七龙珠146.rmvb:24:30,1:11:27,:02:35:52",
+			"/Users/huangyingw/mini/media/usb_backup_crypt_8T_1/cartoon/dragonball/第一��/龙珠 第一部 日语配音/七龙珠146.rmvb:24:30,1:11:27,:02:35:52",
 			[]string{"24:30", "01:11:27", "02:35:52"},
 		},
 		{
@@ -746,7 +745,7 @@ func TestCalculateFileHash(t *testing.T) {
 		// 验证两次计算结果相同
 		assert.Equal(t, hash1, hash2, "相同大小的读取应该产生相同的哈希值")
 
-		// 验证第二次计算使用了缓存
+		// 验证第二次计算使��了缓存
 		hashedKey := fp.generateHashFunc(testFile)
 		cachedHash, err := rdb.Get(ctx, "hashedKeyToFileHash:"+hashedKey).Result()
 		require.NoError(t, err)
@@ -1183,3 +1182,31 @@ func TestFileProcessor_ShouldExclude(t *testing.T) {
 		})
 	}
 }
+
+func TestCalculateFileHashCaching(t *testing.T) {
+	mr, rdb, ctx, fs, fp := setupTestEnvironment(t)
+	defer mr.Close()
+
+	// 创建测试文件
+	testFile := "/test.txt"
+	content := []byte("test content")
+	err := afero.WriteFile(fs, testFile, content, 0644)
+	require.NoError(t, err)
+
+	// 第一次计算哈希
+	hash1, err := fp.calculateFileHash(testFile, ReadLimit)
+	require.NoError(t, err)
+
+	// 第二次计算哈希（应该从缓存获取）
+	hash2, err := fp.calculateFileHash(testFile, ReadLimit)
+	require.NoError(t, err)
+
+	// 验证结果
+	assert.Equal(t, hash1, hash2)
+
+	// 验证缓存
+	hashedKey := fp.generateHashFunc(testFile)
+	cachedHash, err := rdb.Get(ctx, "hashedKeyToFileHash:"+hashedKey).Result()
+	require.NoError(t, err)
+	assert.Equal(t, hash1, cachedHash)
+}
diff --git a/utils_test.go b/utils_test.go
--- ./utils_test.go
+++ ./utils_test.go
@@ -73,46 +73,6 @@ func TestExtractKeywords(t *testing.T) {
 	assert.Equal(t, expectedKeywords, keywords, "Extracted keywords do not match expected keywords")
 }
 
-func TestFindCloseFiles(t *testing.T) {
-	// 创建临时目录
-	tempDir, err := os.MkdirTemp("", "closefiles_test")
-	require.NoError(t, err)
-	defer os.RemoveAll(tempDir)
-
-	// 创建测试用的 fav.log 文件
-	favLog := `100,"test_file_1.txt"
-200,"test_file_2.txt"
-300,"similar_name_1.mp4"
-400,"similar_name_2.mp4"
-500,"totally_different.txt"
-`
-	err = os.WriteFile(filepath.Join(tempDir, "fav.log"), []byte(favLog), 0644)
-	require.NoError(t, err)
-
-	// 创建 CloseFileFinder 实例并处理文件
-	finder := NewCloseFileFinder(tempDir)
-	err = finder.ProcessCloseFiles()
-	require.NoError(t, err)
-
-	// 验证输出文件存在
-	outputPath := filepath.Join(tempDir, "fav.log.close")
-	_, err = os.Stat(outputPath)
-	assert.NoError(t, err)
-
-	// 读取并验证输出内容
-	content, err := os.ReadFile(outputPath)
-	require.NoError(t, err)
-
-	// 验证相似文件被正确识别
-	contentStr := string(content)
-	assert.Contains(t, contentStr, "similar_name_1.mp4")
-	assert.Contains(t, contentStr, "similar_name_2.mp4")
-	assert.Contains(t, contentStr, "相似度:")
-
-	// 验证不相似的文件没有被错误匹配
-	assert.NotContains(t, contentStr, "totally_different.txt")
-}
-
 func TestWalkFiles(t *testing.T) {
 	tempDir, err := ioutil.TempDir("", "test_walk_files")
 	assert.NoError(t, err)
