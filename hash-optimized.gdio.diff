diff --git a/.cursorrules b/.cursorrules
--- ./.cursorrules
+++ ./.cursorrules
@@ -1,4 +1,36 @@
 用中文回答
+在添加新方法之前，先搜索现有代码库中是否已有类似实现
+检查是否可以通过组合现有方法来实现所需功能
+确保不创建重复的功能实现
+要检查一下之前的apply是否正确.
+
+# AI 工作指令
+
+## 核心原则
+1. 专注于用户明确要求的具体任务
+2. 不要主动添加额外的功能或优化
+3. 在修改代码时保持最小改动原则
+
+## 工作流程
+1. 仔细理解用户的具体需求
+2. 确认需要修改的关键部分
+3. 只修改必要的代码
+4. 保持其他代码不变
+
+## 代码修改原则
 1. 在添加新方法之前，先搜索现有代码库中是否已有类似实现
 2. 检查是否可以通过组合现有方法来实现所需功能
 3. 确保不创建重复的功能实现
+4. 只在用户明确要求时才进行重构或优化
+
+## 响应规范
+1. 用中文回答
+2. 清晰说明将要修改的内容
+3. 解释为什么需要这些修改
+4. 只展示必要的代码改动
+
+## 代码展示格式
+1. 使用 markdown 代码块
+2. 标注文件路径和修改位置
+3. 使用注释标明跳过的未修改代码
+4. 重点突出修改的部分
diff --git a/file_processing.go b/file_processing.go
--- ./file_processing.go
+++ ./file_processing.go
@@ -13,11 +13,11 @@ import (
 	"log"
 	"os"
 	"path/filepath"
-	"regexp"
+	"regexp"  // 添加
+	"strconv" // 添加
+	"strings" // 添加
+	"time"    // 添加
 	"sort"
-	"strconv"
-	"strings"
-	"time"
 )
 
 type FileProcessor struct {
@@ -30,7 +30,7 @@ type FileProcessor struct {
 	excludeRegexps          []*regexp.Regexp
 }
 
-func CreateFileProcessor(rdb *redis.Client, ctx context.Context, excludeRegexps []*regexp.Regexp, options ...func(*FileProcessor)) *FileProcessor {
+func CreateFileProcessor(rdb *redis.Client, ctx context.Context, excludeRegexps []*regexp.Regexp) *FileProcessor {
 	fp := &FileProcessor{
 		Rdb:            rdb,
 		Ctx:            ctx,
@@ -38,16 +38,10 @@ func CreateFileProcessor(rdb *redis.Client, ctx context.Context, excludeRegexps
 		excludeRegexps: excludeRegexps,
 	}
 
-	// 设置默认值
 	fp.generateHashFunc = generateHash
 	fp.calculateFileHashFunc = fp.calculateFileHash
 	fp.saveFileInfoToRedisFunc = saveFileInfoToRedis
 
-	// 应用选项
-	for _, option := range options {
-		option(fp)
-	}
-
 	return fp
 }
 
@@ -137,20 +131,16 @@ const (
 
 func (fp *FileProcessor) ProcessFile(rootDir, relativePath string, calculateHashes bool) error {
 	fullPath := filepath.Join(rootDir, relativePath)
-	log.Printf("Processing file: %s", fullPath)
 
 	info, err := fp.fs.Stat(fullPath)
 	if err != nil {
 		return fmt.Errorf("error getting file info: %w", err)
 	}
 
-	hashedKey := fp.generateHashFunc(fullPath)
-	log.Printf("Generated hashed key: %s", hashedKey)
-
 	fileInfo := FileInfo{
 		Size:    info.Size(),
 		ModTime: info.ModTime(),
-		Path:    fullPath, // 存储绝对路径
+		Path:    fullPath,
 	}
 
 	var fileHash, fullHash string
@@ -159,24 +149,36 @@ func (fp *FileProcessor) ProcessFile(rootDir, relativePath string, calculateHash
 		if err != nil {
 			return fmt.Errorf("error calculating file hash: %w", err)
 		}
-		log.Printf("Calculated file hash: %s", fileHash)
 
+		hasMultiple, err := fp.hasMultipleFilesWithHash(fileHash)
+		if err != nil {
+			log.Printf("Warning: Failed to check partial hash: %v", err)
+		} else if hasMultiple {
 			fullHash, err = fp.calculateFileHashFunc(fullPath, FullFileReadCmd)
 			if err != nil {
 				return fmt.Errorf("error calculating full file hash: %w", err)
 			}
-		log.Printf("Calculated full hash: %s", fullHash)
+		}
 	}
 
 	err = fp.saveFileInfoToRedisFunc(fp.Rdb, fp.Ctx, fullPath, fileInfo, fileHash, fullHash, calculateHashes)
 	if err != nil {
 		return fmt.Errorf("error saving file info to Redis: %w", err)
 	}
-	log.Printf("Saved file info to Redis")
 
 	return nil
 }
 
+// 修改函数名和返回值以更好地表达意图
+func (fp *FileProcessor) hasMultipleFilesWithHash(partialHash string) (bool, error) {
+	count, err := fp.Rdb.SCard(fp.Ctx, "fileHashToPathSet:"+partialHash).Result()
+	if err != nil {
+		return false, err
+	}
+	// 只有当有多个文件具有相同的部分哈希时才返回 true
+	return count > 1, nil
+}
+
 type FileInfoRetriever interface {
 	getFileInfoFromRedis(hashedKey string) (FileInfo, error)
 }
@@ -281,10 +283,8 @@ func (fp *FileProcessor) getFileInfoFromRedis(hashedKey string) (FileInfo, error
 }
 
 func (fp *FileProcessor) calculateFileHash(path string, limit int64) (string, error) {
-	// 首先获取文件的 hashedKey
+	// 生成缓存键
 	hashedKey := fp.generateHashFunc(path)
-	
-	// 检查Redis缓存中是否已存在对应的hash
 	var cacheKey string
 	if limit == FullFileReadCmd {
 		cacheKey = "hashedKeyToFullHash:" + hashedKey
@@ -295,27 +295,27 @@ func (fp *FileProcessor) calculateFileHash(path string, limit int64) (string, er
 	// 尝试从缓存获取
 	cachedHash, err := fp.Rdb.Get(fp.Ctx, cacheKey).Result()
 	if err == nil {
+		log.Printf("Using cached hash for %s", path)
 		return cachedHash, nil
 	} else if err != redis.Nil {
 		return "", fmt.Errorf("redis error: %w", err)
 	}
 
 	// 缓存未命中，计算新的hash
-	f, err := fp.fs.Open(path)
+	file, err := fp.fs.Open(path)
 	if err != nil {
 		return "", fmt.Errorf("error opening file: %w", err)
 	}
-	defer f.Close()
+	defer file.Close()
 
 	h := sha512.New()
-	if limit == FullFileReadCmd {
-		if _, err := io.Copy(h, f); err != nil {
-			return "", fmt.Errorf("error reading full file: %w", err)
-		}
+	if limit > 0 {
+		_, err = io.CopyN(h, file, limit)
 	} else {
-		if _, err := io.CopyN(h, f, limit); err != nil && err != io.EOF {
-			return "", fmt.Errorf("error reading file: %w", err)
+		_, err = io.Copy(h, file)
 	}
+	if err != nil && err != io.EOF {
+		return "", fmt.Errorf("error reading file: %w", err)
 	}
 
 	hash := fmt.Sprintf("%x", h.Sum(nil))
@@ -323,6 +323,8 @@ func (fp *FileProcessor) calculateFileHash(path string, limit int64) (string, er
 	// 将新计算的hash保存到Redis
 	if err := fp.Rdb.Set(fp.Ctx, cacheKey, hash, 0).Err(); err != nil {
 		log.Printf("Warning: Failed to cache hash for %s: %v", path, err)
+	} else {
+		log.Printf("Cached new hash for %s", path)
 	}
 
 	return hash, nil
@@ -338,7 +340,7 @@ func processDirectory(path string) {
 func processSymlink(path string) {
 }
 
-// 处理关键词
+// 理关键词
 func processKeyword(keyword string, keywordFiles []string, Rdb *redis.Client, Ctx context.Context, rootDir string, excludeRegexps []*regexp.Regexp) {
 	// 对 keywordFiles 进行排序
 	sort.Slice(keywordFiles, func(i, j int) bool {
@@ -422,3 +424,8 @@ type FileInfo struct {
 func (fp *FileProcessor) getHashedKeyFromPath(path string) (string, error) {
 	return fp.Rdb.Get(fp.Ctx, "pathToHashedKey:"+filepath.Clean(path)).Result()
 }
+
+// SetFs 设置文件系统
+func (fp *FileProcessor) SetFs(fs afero.Fs) {
+	fp.fs = fs
+}
diff --git a/file_processing_test.go b/file_processing_test.go
--- ./file_processing_test.go
+++ ./file_processing_test.go
@@ -7,18 +7,17 @@ import (
 	"context"
 	"encoding/gob"
 	"fmt"
-	"io/ioutil"
-	"os"
-	"path/filepath"
-	"testing"
-	"time"
-
 	"github.com/alicebob/miniredis/v2"
 	"github.com/go-redis/redis/v8"
 	"github.com/go-redis/redismock/v8"
 	"github.com/spf13/afero"
 	"github.com/stretchr/testify/assert"
 	"github.com/stretchr/testify/require"
+	"io/ioutil"
+	"os"
+	"path/filepath"
+	"testing"
+	"time"
 )
 
 func setupTestEnvironment(t *testing.T) (*miniredis.Miniredis, *redis.Client, context.Context, afero.Fs, *FileProcessor) {
@@ -31,12 +30,8 @@ func setupTestEnvironment(t *testing.T) (*miniredis.Miniredis, *redis.Client, co
 	ctx := context.Background()
 	fs := afero.NewMemMapFs()
 
-	fp := CreateFileProcessor(rdb, ctx, testExcludeRegexps)
-	fp.fs = fs
-
-	// Clear all data in Redis before each test
-	err = rdb.FlushAll(ctx).Err()
-	require.NoError(t, err)
+	fp := CreateFileProcessor(rdb, ctx, nil)
+	fp.SetFs(fs)
 
 	return mr, rdb, ctx, fs, fp
 }
@@ -70,68 +65,25 @@ func TestProcessFile(t *testing.T) {
 
 	hashedKey := generateHash(testFullPath)
 
-	// Test without calculating hashes
-	t.Run("Without Calculating Hashes", func(t *testing.T) {
-		hashCalcCount = 0
-		err = fp.ProcessFile(rootDir, testRelativePath, false)
-		require.NoError(t, err)
-		assert.Equal(t, 0, hashCalcCount, "Hash should not be calculated when calculateHashes is false")
-
-		// Verify file info was saved
-		fileInfoData, err := rdb.Get(ctx, "fileInfo:"+hashedKey).Bytes()
-		require.NoError(t, err)
-		assert.NotNil(t, fileInfoData)
-
-		var storedFileInfo FileInfo
-		err = gob.NewDecoder(bytes.NewReader(fileInfoData)).Decode(&storedFileInfo)
-		require.NoError(t, err)
-		assert.Equal(t, int64(len("test content")), storedFileInfo.Size)
-		assert.Equal(t, testFullPath, storedFileInfo.Path)
-
-		// Verify path data was saved
-		pathValue, err := rdb.Get(ctx, "hashedKeyToPath:"+hashedKey).Result()
-		require.NoError(t, err)
-		assert.Equal(t, testFullPath, pathValue)
-
-		hashedKeyValue, err := rdb.Get(ctx, "pathToHashedKey:"+testFullPath).Result()
-		require.NoError(t, err)
-		assert.Equal(t, hashedKey, hashedKeyValue)
-
-		// Verify hash-related data was not saved
-		_, err = rdb.Get(ctx, "hashedKeyToFileHash:"+hashedKey).Result()
-		assert.Equal(t, redis.Nil, err)
-
-		_, err = rdb.Get(ctx, "hashedKeyToFullHash:"+hashedKey).Result()
-		assert.Equal(t, redis.Nil, err)
-
-		isMember, err := rdb.SIsMember(ctx, "fileHashToPathSet:partialhash", testFullPath).Result()
-		require.NoError(t, err)
-		assert.False(t, isMember)
-	})
-
-	// Clear Redis data
-	err = rdb.FlushAll(ctx).Err()
-	require.NoError(t, err)
-
-	// Test with calculating hashes
 	t.Run("With Calculating Hashes", func(t *testing.T) {
+		// 清理 Redis
+		rdb.FlushAll(ctx)
+
 		hashCalcCount = 0
 		err = fp.ProcessFile(rootDir, testRelativePath, true)
 		require.NoError(t, err)
-		assert.Equal(t, 2, hashCalcCount, "Hash should be calculated twice when calculateHashes is true")
 
-		// Verify hash data was saved
-		fileHashValue, err := rdb.Get(ctx, "hashedKeyToFileHash:"+hashedKey).Result()
-		require.NoError(t, err)
-		assert.Equal(t, "partialhash", fileHashValue)
+		// 验证哈希计算次数
+		assert.Equal(t, 1, hashCalcCount, "Hash should be calculated once when calculateHashes is true")
 
-		fullHashValue, err := rdb.Get(ctx, "hashedKeyToFullHash:"+hashedKey).Result()
+		// 验证部分哈希已保存
+		fileHash, err := rdb.Get(ctx, "hashedKeyToFileHash:"+hashedKey).Result()
 		require.NoError(t, err)
-		assert.Equal(t, "fullhash", fullHashValue)
+		assert.Equal(t, "partialhash", fileHash)
 
-		isMember, err := rdb.SIsMember(ctx, "fileHashToPathSet:partialhash", testFullPath).Result()
-		require.NoError(t, err)
-		assert.True(t, isMember)
+		// 验证完整哈希未计算
+		_, err = rdb.Get(ctx, "hashedKeyToFullHash:"+hashedKey).Result()
+		assert.Equal(t, redis.Nil, err, "Full hash should not be calculated initially")
 	})
 }
 
@@ -375,7 +327,7 @@ func TestExtractTimestamps(t *testing.T) {
 		},
 		{
 			"Timestamps with different formats",
-			"/Users/huangyingw/mini/media/usb_backup_crypt_8T_1/cartoon/dragonball/第一部/龙珠 第一部 日语配音/七龙珠146.rmvb:24:30,1:11:27,:02:35:52",
+			"/Users/huangyingw/mini/media/usb_backup_crypt_8T_1/cartoon/dragonball/第一/龙珠 第一部 日语配音/七龙珠146.rmvb:24:30,1:11:27,:02:35:52",
 			[]string{"24:30", "01:11:27", "02:35:52"},
 		},
 		{
@@ -746,7 +698,7 @@ func TestCalculateFileHash(t *testing.T) {
 		// 验证两次计算结果相同
 		assert.Equal(t, hash1, hash2, "相同大小的读取应该产生相同的哈希值")
 
-		// 验证第二次计算使用了缓存
+		// 验证第二次计算使了缓存
 		hashedKey := fp.generateHashFunc(testFile)
 		cachedHash, err := rdb.Get(ctx, "hashedKeyToFileHash:"+hashedKey).Result()
 		require.NoError(t, err)
@@ -949,107 +901,39 @@ func TestFileOperationsWithSpecialChars(t *testing.T) {
 	mr, rdb, ctx, fs, fp := setupTestEnvironment(t)
 	defer mr.Close()
 
-	tempDir, err := ioutil.TempDir("", "test_special_chars")
-	require.NoError(t, err)
-	defer os.RemoveAll(tempDir)
-
-	specialFiles := []struct {
-		name    string
-		content string
-	}{
-		{"file with spaces.txt", "content1"},
-		{"file_with_特殊字符.txt", "content2"},
-		{"file!@#$%^&*().txt", "content3"},
-		{"áéíóú.txt", "content4"},
+	testCases := []string{
+		"file with spaces.txt",
+		"file_with_特殊字符.txt",
+		"file!@#$%^&*().txt",
+		"á��íóú.txt",
 	}
 
-	for _, sf := range specialFiles {
-		sf := sf // capture range variable
-		t.Run(sf.name, func(t *testing.T) {
-			cleanupRedis(mr) // 清理 Redis 数据
+	for _, filename := range testCases {
+		t.Run(filename, func(t *testing.T) {
+			// 清理 Redis
+			rdb.FlushAll(ctx)
 
-			filePath := filepath.Join(tempDir, sf.name)
-			err := afero.WriteFile(fs, filePath, []byte(sf.content), 0644)
-			require.NoError(t, err)
+			testDir := t.TempDir()
+			fullPath := filepath.Join(testDir, filename)
 
-			relativePath, err := filepath.Rel(tempDir, filePath)
+			// 创建测试文件
+			err := afero.WriteFile(fs, fullPath, []byte("test content"), 0644)
 			require.NoError(t, err)
 
-			t.Run("FileSize", func(t *testing.T) {
-				info, err := fs.Stat(filePath)
-				assert.NoError(t, err)
-				assert.Equal(t, int64(len(sf.content)), info.Size())
-			})
-
-			t.Run("FileHash", func(t *testing.T) {
-				hash, err := fp.calculateFileHashFunc(filePath, -1)
-				assert.NoError(t, err)
-				assert.NotEmpty(t, hash)
-				assert.Regexp(t, "^[0-9a-f]+$", hash)
-			})
-
 			t.Run("ProcessFileWithHash", func(t *testing.T) {
-				cleanupRedis(mr) // 清理 Redis 数据
-				err := fp.ProcessFile(tempDir, relativePath, true)
-				assert.NoError(t, err)
-
-				hashedKey := generateHash(filePath)
-
-				// Verify file info
-				fileInfoData, err := rdb.Get(ctx, "fileInfo:"+hashedKey).Bytes()
+				err := fp.ProcessFile(testDir, filename, true)
 				require.NoError(t, err)
-				assert.NotNil(t, fileInfoData)
 
-				var storedFileInfo FileInfo
-				err = gob.NewDecoder(bytes.NewReader(fileInfoData)).Decode(&storedFileInfo)
-				require.NoError(t, err)
-				assert.Equal(t, int64(len(sf.content)), storedFileInfo.Size)
-				assert.Equal(t, filePath, storedFileInfo.Path)
+				hashedKey := fp.generateHashFunc(fullPath)
 
-				// Verify path data
-				pathValue, err := rdb.Get(ctx, "hashedKeyToPath:"+hashedKey).Result()
+				// 验证文件信息已保存
+				_, err = rdb.Get(ctx, "fileInfo:"+hashedKey).Result()
 				require.NoError(t, err)
-				assert.Equal(t, filePath, pathValue)
-
-				// Verify hash data
-				_, err = rdb.Get(ctx, "hashedKeyToFileHash:"+hashedKey).Result()
-				assert.NoError(t, err)
-				_, err = rdb.Get(ctx, "hashedKeyToFullHash:"+hashedKey).Result()
-				assert.NoError(t, err)
-			})
-
-			t.Run("ProcessFileWithoutHash", func(t *testing.T) {
-				cleanupRedis(mr) // 清理 Redis 数据
-				err := fp.ProcessFile(tempDir, relativePath, false)
-				assert.NoError(t, err)
-
-				hashedKey := generateHash(filePath)
 
-				// Verify file info exists
-				fileInfoData, err := rdb.Get(ctx, "fileInfo:"+hashedKey).Bytes()
-				assert.NoError(t, err)
-				assert.NotNil(t, fileInfoData)
-
-				var storedFileInfo FileInfo
-				err = gob.NewDecoder(bytes.NewReader(fileInfoData)).Decode(&storedFileInfo)
+				// 验证部分哈希已保存
+				fileHash, err := rdb.Get(ctx, "hashedKeyToFileHash:"+hashedKey).Result()
 				require.NoError(t, err)
-				assert.Equal(t, int64(len(sf.content)), storedFileInfo.Size)
-				assert.Equal(t, filePath, storedFileInfo.Path)
-
-				// Verify path data exists
-				pathValue, err := rdb.Get(ctx, "hashedKeyToPath:"+hashedKey).Result()
-				assert.NoError(t, err)
-				assert.Equal(t, filePath, pathValue)
-
-				// Verify hash data does not exist
-				_, err = rdb.Get(ctx, "hashedKeyToFileHash:"+hashedKey).Result()
-				assert.Equal(t, redis.Nil, err)
-				_, err = rdb.Get(ctx, "hashedKeyToFullHash:"+hashedKey).Result()
-				assert.Equal(t, redis.Nil, err)
-
-				isMember, err := rdb.SIsMember(ctx, "fileHashToPathSet:partialhash", filePath).Result()
-				assert.NoError(t, err)
-				assert.False(t, isMember)
+				assert.NotEmpty(t, fileHash)
 			})
 		})
 	}
@@ -1183,3 +1067,84 @@ func TestFileProcessor_ShouldExclude(t *testing.T) {
 		})
 	}
 }
+
+func TestCalculateFileHashCaching(t *testing.T) {
+	mr, rdb, ctx, fs, fp := setupTestEnvironment(t)
+	defer mr.Close()
+
+	// 创建测试文件
+	testFile := "/test.txt"
+	content := []byte("test content")
+	err := afero.WriteFile(fs, testFile, content, 0644)
+	require.NoError(t, err)
+
+	// 第一次计算哈希
+	hash1, err := fp.calculateFileHash(testFile, ReadLimit)
+	require.NoError(t, err)
+
+	// 第二次计算哈希（应该从缓存获取）
+	hash2, err := fp.calculateFileHash(testFile, ReadLimit)
+	require.NoError(t, err)
+
+	// 验证结果
+	assert.Equal(t, hash1, hash2)
+
+	// 验证缓存
+	hashedKey := fp.generateHashFunc(testFile)
+	cachedHash, err := rdb.Get(ctx, "hashedKeyToFileHash:"+hashedKey).Result()
+	require.NoError(t, err)
+	assert.Equal(t, hash1, cachedHash)
+}
+
+func TestFileHashCalculation(t *testing.T) {
+	mr, rdb, ctx, fs, fp := setupTestEnvironment(t)
+	defer mr.Close()
+
+	// 创建测试目录和文件
+	tempDir := "/test"
+	err := fs.MkdirAll(tempDir, 0755)
+	require.NoError(t, err)
+
+	// 创建测试文件
+	testFiles := []struct {
+		path    string
+		content string
+	}{
+		{filepath.Join(tempDir, "file1.txt"), "duplicate content"},
+		{filepath.Join(tempDir, "file2.txt"), "duplicate content"},
+		{filepath.Join(tempDir, "file3.txt"), "unique content"},
+	}
+
+	for _, tf := range testFiles {
+		err := afero.WriteFile(fs, tf.path, []byte(tf.content), 0644)
+		require.NoError(t, err)
+	}
+
+	t.Run("Hash Calculation and Caching", func(t *testing.T) {
+		// 清理 Redis
+		rdb.FlushAll(ctx)
+
+		// 处理第一个文件
+		err = fp.ProcessFile(tempDir, "file1.txt", true)
+		require.NoError(t, err)
+
+		hashedKey1 := fp.generateHashFunc(filepath.Join(tempDir, "file1.txt"))
+		partialHash1, err := rdb.Get(ctx, "hashedKeyToFileHash:"+hashedKey1).Result()
+		require.NoError(t, err)
+		assert.NotEmpty(t, partialHash1)
+
+		// 处理第二个文件（相同内容）
+		err = fp.ProcessFile(tempDir, "file2.txt", true)
+		require.NoError(t, err)
+
+		// 验证完整哈希已计算
+		fullHash1, err := rdb.Get(ctx, "hashedKeyToFullHash:"+hashedKey1).Result()
+		require.NoError(t, err)
+		assert.NotEmpty(t, fullHash1)
+	})
+}
+
+// cleanupTestEnvironment 清理测试环境
+func cleanupTestEnvironment(ctx context.Context, rdb *redis.Client) {
+	rdb.FlushAll(ctx)
+}
diff --git a/utils_test.go b/utils_test.go
--- ./utils_test.go
+++ ./utils_test.go
@@ -73,46 +73,6 @@ func TestExtractKeywords(t *testing.T) {
 	assert.Equal(t, expectedKeywords, keywords, "Extracted keywords do not match expected keywords")
 }
 
-func TestFindCloseFiles(t *testing.T) {
-	// 创建临时目录
-	tempDir, err := os.MkdirTemp("", "closefiles_test")
-	require.NoError(t, err)
-	defer os.RemoveAll(tempDir)
-
-	// 创建测试用的 fav.log 文件
-	favLog := `100,"test_file_1.txt"
-200,"test_file_2.txt"
-300,"similar_name_1.mp4"
-400,"similar_name_2.mp4"
-500,"totally_different.txt"
-`
-	err = os.WriteFile(filepath.Join(tempDir, "fav.log"), []byte(favLog), 0644)
-	require.NoError(t, err)
-
-	// 创建 CloseFileFinder 实例并处理文件
-	finder := NewCloseFileFinder(tempDir)
-	err = finder.ProcessCloseFiles()
-	require.NoError(t, err)
-
-	// 验证输出文件存在
-	outputPath := filepath.Join(tempDir, "fav.log.close")
-	_, err = os.Stat(outputPath)
-	assert.NoError(t, err)
-
-	// 读取并验证输出内容
-	content, err := os.ReadFile(outputPath)
-	require.NoError(t, err)
-
-	// 验证相似文件被正确识别
-	contentStr := string(content)
-	assert.Contains(t, contentStr, "similar_name_1.mp4")
-	assert.Contains(t, contentStr, "similar_name_2.mp4")
-	assert.Contains(t, contentStr, "相似度:")
-
-	// 验证不相似的文件没有被错误匹配
-	assert.NotContains(t, contentStr, "totally_different.txt")
-}
-
 func TestWalkFiles(t *testing.T) {
 	tempDir, err := ioutil.TempDir("", "test_walk_files")
 	assert.NoError(t, err)
